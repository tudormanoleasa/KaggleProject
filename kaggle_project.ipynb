{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nimport copy\n\nimport sklearn\nimport numpy as np \nimport pandas as pd \nimport os\nimport scipy\nfrom scipy.stats import chi2_contingency, ttest_ind, f_oneway, levene\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.anova import anova_lm\nimport seaborn\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import hist\nfrom mpl_toolkits import mplot3d\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits import mplot3d\nfrom sklearn.manifold import TSNE\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules\nfrom sklearn.metrics import classification_report, balanced_accuracy_score, roc_curve\n\n\npd.set_option(\"max_colwidth\", None)\n\nimport imblearn\n# import optunity\n\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\nfrom sklearn.feature_selection import f_classif, chi2, SelectKBest, RFECV\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, StratifiedKFold, RandomizedSearchCV, cross_validate , RepeatedKFold\n\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.naive_bayes import GaussianNB, CategoricalNB\n\nfrom scipy.stats import randint\n\nfrom sklearn.svm import SVC","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-28T11:59:52.260669Z","iopub.execute_input":"2022-06-28T11:59:52.261000Z","iopub.status.idle":"2022-06-28T11:59:54.926456Z","shell.execute_reply.started":"2022-06-28T11:59:52.260929Z","shell.execute_reply":"2022-06-28T11:59:54.925416Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"path = \"../input/hr-analytics-job-change-of-data-scientists\"\n_, test, train = os.listdir(\"../input/hr-analytics-job-change-of-data-scientists\")\ntrain_df = pd.read_csv(path + \"/\" + train)\ntest_df = pd.read_csv(path + \"/\" + test)\nprint(\"Size of training set: \", train_df.shape[0])\ntrain_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:59:54.928547Z","iopub.execute_input":"2022-06-28T11:59:54.928904Z","iopub.status.idle":"2022-06-28T11:59:55.107801Z","shell.execute_reply.started":"2022-06-28T11:59:54.928866Z","shell.execute_reply":"2022-06-28T11:59:55.106686Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"''' \ncity                     Categorical Nominal Variable    (many possible values)\ncity_development_index   Quantitative Continous Variable (many possible values)\ngender                   Categorical Nominal Variable    (3 possible values)    (the 4th value is nan!!)\nrelevent_experience      Categorical Nominal Variable    (2 possible values)\nenrolled_university      Categorical Ordinal Variable    (3 possible values)    (the 4th value is nan!!)\neducation_level          Categorical Ordinal Variable    (5 possible values)    (the 6th value is nan!!)\nmajor_discipline         Categorical Nominal Variable    (6 possible values)    (the 7th value is nan!!)\nexperience               Quantitative Discrete Variable                         (has nan!!)\ncompany_size             Categorical Ordinal Variable                           (has nan!!)\ncompany_type             Categorical Nominal Variable    (6 possible values)    (the 7th value is nan!!)\nlast_new_job             Categorical Ordinal Variable    (6 possible values)    (the 7th value is nan!!)\ntraining_hours           Quantitave Continous Variable   (many possible values)\ntarget                   Binary Output Variabile 0/1 \n'''\n\nfor column in train_df.columns:\n    uniques = train_df[column].unique()\n    print(\"Column: \\'\" + column + '\\'')\n    print(\"Domain of \\'\" + column + \"\\':\", uniques)\n    print(\"Number of unique values:\", len(uniques))\n    if np.nan in uniques.tolist():\n        print(column + \" has nan: Yes\")\n    else:\n        print(column + \" has nan: No\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:59:55.109221Z","iopub.execute_input":"2022-06-28T11:59:55.109567Z","iopub.status.idle":"2022-06-28T11:59:55.160175Z","shell.execute_reply.started":"2022-06-28T11:59:55.109538Z","shell.execute_reply":"2022-06-28T11:59:55.159331Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:59:55.161565Z","iopub.execute_input":"2022-06-28T11:59:55.161932Z","iopub.status.idle":"2022-06-28T11:59:55.190344Z","shell.execute_reply.started":"2022-06-28T11:59:55.161897Z","shell.execute_reply":"2022-06-28T11:59:55.189296Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"quantitative = ['city_development_index', 'experience', 'training_hours']\ncategorical = ['city', 'gender', 'relevent_experience', 'enrolled_university', 'education_level', 'major_discipline', 'company_size',\n               'company_type', 'last_new_job', 'target']\n_ = dict(zip(categorical, len(categorical) * [\"miss\"]))\ntrain_df.fillna(value=_, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:59:55.193343Z","iopub.execute_input":"2022-06-28T11:59:55.193576Z","iopub.status.idle":"2022-06-28T11:59:55.210359Z","shell.execute_reply.started":"2022-06-28T11:59:55.193554Z","shell.execute_reply":"2022-06-28T11:59:55.209307Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Chi-square test of independence of variables\n# H_0 = the variables are independent\nfor i in range(0, len(categorical)):\n    for j in range(i + 1, len(categorical)):\n        contingency_table = pd.crosstab(train_df[categorical[i]][train_df[categorical[i]] != 'miss'], \n                                        train_df[categorical[j]][train_df[categorical[j]] != 'miss'])\n        chi_statistic, p_value, df, expected_table = chi2_contingency(contingency_table)\n        alpha = 0.05\n        if p_value < alpha:\n            print(categorical[i] + \" and \" + categorical[j] + \": we reject H_0\")\n        else:\n            print(categorical[i] + \" and \" + categorical[j] + \": we DON'T reject H_0\")","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:59:55.213645Z","iopub.execute_input":"2022-06-28T11:59:55.213931Z","iopub.status.idle":"2022-06-28T11:59:56.159457Z","shell.execute_reply.started":"2022-06-28T11:59:55.213904Z","shell.execute_reply":"2022-06-28T11:59:56.158274Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Inference on 2 population means, sigmas not known \n# Therefore, t-test\nfor column_1 in (\"relevent_experience\", \"target\"):\n    for column_2 in (\"training_hours\", \"city_development_index\"):\n        uniques = train_df[column_1].unique()\n        sample_pop_1 = train_df[[column_2]][train_df[column_1] == uniques[0]]\n        sample_pop_2 = train_df[column_2][train_df[column_1] == uniques[1]]\n        print(\"Sample size from first population: \" + str(len(sample_pop_1)))\n        print(\"Sample size from second population: \" + str(len(sample_pop_2)))\n        print(\"The samples are independent simple random samples ✔\")\n        print(\"The populations are normally distributed or sample size is big enough (CLT applies) ✔\")\n        var_1 = float(sample_pop_1.var())\n        var_2 = float(sample_pop_2.var())\n        if var_1 < var_2:\n            aux = var_1\n            var_1 = var_2\n            var_2 = var_1\n        F_statistic = var_1 / var_2\n        df1 = len(sample_pop_1) - 1\n        df2 = len(sample_pop_2) - 1\n        p_value = scipy.stats.f.sf(F_statistic, df1, df2)\n        alpha = 0.05\n        ok = 0\n        if p_value < alpha:\n            print(\"Population variances are not equal ✖\")\n            ok = 1\n        else:\n            print(\"Population variances are equal ✔\")\n        t_test =  ttest_ind(sample_pop_1, sample_pop_2, equal_var=(lambda elem : False if elem == 1 else True)(ok)) # basci t-test / Welch t test\n        if t_test.pvalue[0] < alpha:\n            print(column_1 + \", \" + column_2 + \": Population means are not equal ✖\", end=\"\\n\\n\")\n        else:\n            print(column_1 + \", \" + column_2 + \": Population means are equal ✔\", end=\"\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:59:56.160944Z","iopub.execute_input":"2022-06-28T11:59:56.161265Z","iopub.status.idle":"2022-06-28T11:59:56.207556Z","shell.execute_reply.started":"2022-06-28T11:59:56.161225Z","shell.execute_reply":"2022-06-28T11:59:56.206382Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Inference on 3 or more population means, sigmas not known\n# ANOVA one-way\nfor column_1 in ('training_hours', 'city_development_index'):\n    for column_2 in ('gender', 'enrolled_university', 'education_level', 'major_discipline', 'company_type', 'last_new_job'):\n        uniques = train_df[column_2].unique().tolist()\n        del uniques[uniques.index('miss')]\n        variants = []\n        for value in uniques:\n            variants.append(train_df[column_1][train_df[column_2] == value])\n        print(\"Sample sizes from our populations: \", [len(_) for _ in variants])\n        print(\"The samples are independent simple random samples ✔\")\n        print(\"The populations are normally distributed or sample size is big enough (CLT applies) ✔\")\n        levene_test = levene(*variants)\n        if levene_test.pvalue < alpha:\n            print(\"Population variances are not equal ✖\", end=\"\\n\\n\")\n        else:\n            print(\"Population variances are equal ✔\")\n            anova_oneway = f_oneway(*variants)\n            if anova_oneway.pvalue < alpha:\n                print(\"Population means are not equal ✖\", end=\"\\n\\n\")\n            else:\n                print(column_1 + \", \" + column_2 + \": Population means are equal ✔\", end=\"\\n\\n\")\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:59:56.208510Z","iopub.execute_input":"2022-06-28T11:59:56.208703Z","iopub.status.idle":"2022-06-28T11:59:56.404318Z","shell.execute_reply.started":"2022-06-28T11:59:56.208681Z","shell.execute_reply":"2022-06-28T11:59:56.403193Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"stats = train_df[['city_development_index', 'training_hours']].describe()\nstats.loc['median'] = train_df[['city_development_index', 'training_hours']].median()\nstats.loc['mod'] = train_df[['city_development_index', 'training_hours']].mode().loc[0]\nstats","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:59:56.405426Z","iopub.execute_input":"2022-06-28T11:59:56.405703Z","iopub.status.idle":"2022-06-28T11:59:56.441120Z","shell.execute_reply.started":"2022-06-28T11:59:56.405672Z","shell.execute_reply":"2022-06-28T11:59:56.439981Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"f = plt.figure(figsize=(5, 5))\nplt.matshow(train_df[[\"city_development_index\", \"training_hours\"]].corr(), fignum=f.number)\nplt.xticks(range(0, 2), [\"city_development_index\", \"training_hours\"], fontsize=14, rotation=10)\nplt.yticks(range(0, 2), [\"city_development_index\", \"training_hours\"], fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:59:56.442408Z","iopub.execute_input":"2022-06-28T11:59:56.442695Z","iopub.status.idle":"2022-06-28T11:59:56.686984Z","shell.execute_reply.started":"2022-06-28T11:59:56.442667Z","shell.execute_reply":"2022-06-28T11:59:56.685868Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# simple histograms\nfig = plt.figure(figsize = (15,5))\nax = fig.gca()\n_ = train_df.hist(column=[\"city_development_index\", \"training_hours\"], bins = 10, ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:59:56.688369Z","iopub.execute_input":"2022-06-28T11:59:56.688767Z","iopub.status.idle":"2022-06-28T11:59:57.105927Z","shell.execute_reply.started":"2022-06-28T11:59:56.688730Z","shell.execute_reply":"2022-06-28T11:59:57.105005Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# simple boxplots\nplt.figure(figsize = (15,5)).subplots_adjust(hspace=.5) # subplots_adjust adds space between histograms\nnr = 0\nfor i in range(0, len(quantitative)):\n    if quantitative[i] == 'experience':\n        continue\n    nr += 1\n    plt.subplot(1, 2, nr)\n    plt.boxplot(x=train_df[quantitative[i]].tolist())\n    plt.title(quantitative[i])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:59:57.107058Z","iopub.execute_input":"2022-06-28T11:59:57.107567Z","iopub.status.idle":"2022-06-28T11:59:57.653467Z","shell.execute_reply.started":"2022-06-28T11:59:57.107542Z","shell.execute_reply":"2022-06-28T11:59:57.652334Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# conditioned histograms\nplt.figure(figsize = (25, 25)).subplots_adjust(hspace=.5) # subplots_adjust adds space between plots\nnr = 0\nfor i in range(0, len(quantitative)):\n    if quantitative[i] == 'experience':\n        continue\n    for j in range(0, len(categorical)):\n        if categorical[j] == 'city':\n            continue\n        nr += 1\n        plt.subplot(6, 3, nr)\n        labels = train_df[categorical[j]].unique().tolist()\n        hist_list = []\n        for label in labels:\n            hist_list.append(train_df[quantitative[i]][train_df[categorical[j]] == label])\n        bins = 10\n        for index in range(0, len(hist_list)):\n            plt.hist(hist_list[index], bins, alpha=0.5, label=labels[index])\n        plt.title(quantitative[i] + \" conditioned by:\" + categorical[j])\n        plt.legend(loc='best')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T11:59:57.654704Z","iopub.execute_input":"2022-06-28T11:59:57.654998Z","iopub.status.idle":"2022-06-28T12:00:03.954369Z","shell.execute_reply.started":"2022-06-28T11:59:57.654970Z","shell.execute_reply":"2022-06-28T12:00:03.953049Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# scatter plot\nfig = plt.figure(figsize = (15,5))\nax = fig.gca()\n_ = train_df[train_df['target']==1].plot.scatter(x=\"city_development_index\", y=\"training_hours\", c=\"DarkBlue\", ax=ax, label=\"target=1\")\n_ = train_df[train_df['target']==0].plot.scatter(x=\"city_development_index\", y=\"training_hours\", c=\"LightGreen\", ax=ax, label=\"target=0\")","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:03.955776Z","iopub.execute_input":"2022-06-28T12:00:03.956147Z","iopub.status.idle":"2022-06-28T12:00:05.148404Z","shell.execute_reply.started":"2022-06-28T12:00:03.956107Z","shell.execute_reply":"2022-06-28T12:00:05.147175Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(15, 5))\nax = plt.axes(projection=\"3d\")\nax.scatter3D(xs=train_df['city_development_index'], ys=train_df['training_hours'], zs=np.random.normal(0, 5, (1, len(train_df))), color=\"red\")\nplt.title('simple 3D scatter plot')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:05.149918Z","iopub.execute_input":"2022-06-28T12:00:05.150304Z","iopub.status.idle":"2022-06-28T12:00:05.661691Z","shell.execute_reply.started":"2022-06-28T12:00:05.150266Z","shell.execute_reply":"2022-06-28T12:00:05.660727Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"'''\n# conditioned boxplot\nfig = plt.figure(figsize = (15,5))\nax = fig.gca()\n_ = train_df.boxplot(column='training_hours', ax=ax, by='gender')\n'''\n\n# conditioned boxplots\nfor i in range(0, len(quantitative)):\n    if quantitative[i] == 'experience':\n        continue\n    for j in range(0, len(categorical)):\n        if categorical[j] == 'city':\n            continue\n        fig = plt.figure(figsize = (17,5))\n        ax = fig.gca()\n        _ = train_df.boxplot(column=quantitative[i], ax=ax, by=categorical[j])","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:05.663138Z","iopub.execute_input":"2022-06-28T12:00:05.663558Z","iopub.status.idle":"2022-06-28T12:00:09.715542Z","shell.execute_reply.started":"2022-06-28T12:00:05.663493Z","shell.execute_reply":"2022-06-28T12:00:09.714005Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# conditioned piechart\nplt.figure(figsize = (20,20)).subplots_adjust(hspace=.5) # subplots_adjust adds space between plots\nfor i in range(0, len(categorical)):\n    if categorical[i] == 'city':\n        continue\n    plt.subplot(3, 3, i)\n    groupby_obj = train_df.groupby(by=categorical[i])\n    labels = train_df[categorical[i]].unique().tolist()\n    pie_list = []\n    for label in labels:\n        pie_list.append(len(groupby_obj.get_group(label)))\n    patches, texts = plt.pie(pie_list, startangle=90, frame=True)\n    plt.legend(patches, labels, loc='best')\n    plt.title(categorical[i])\n    plt.axis('equal')\n    plt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:09.717111Z","iopub.execute_input":"2022-06-28T12:00:09.717502Z","iopub.status.idle":"2022-06-28T12:00:14.285296Z","shell.execute_reply.started":"2022-06-28T12:00:09.717464Z","shell.execute_reply":"2022-06-28T12:00:14.284059Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# bar plots\nplt.figure(figsize = (20,20)).subplots_adjust(hspace=.5) # subplots_adjust adds space between histograms\nfor i in range(0, len(categorical)):\n    if categorical[i] == 'city':\n        continue\n    plt.subplot(3, 3, i)\n    labels = train_df[categorical[i]].unique().tolist()\n    bar_list = []\n    for label in labels:\n        bar_list.append(len(train_df[categorical[i]][train_df[categorical[i]] == label]))\n    plt.bar(labels, bar_list)\n    plt.title(categorical[i])\n    plt.xticks(rotation = 45) # rotates the labels a little bit so that they don't overlap\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:14.286506Z","iopub.execute_input":"2022-06-28T12:00:14.286808Z","iopub.status.idle":"2022-06-28T12:00:16.144239Z","shell.execute_reply.started":"2022-06-28T12:00:14.286778Z","shell.execute_reply":"2022-06-28T12:00:16.143309Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df_tsne_x = train_df[['city_development_index', 'training_hours']]\ndf_tsne_y = train_df['target']\n\ntsne = TSNE(n_components=2, n_iter=300)\ntsne_results = tsne.fit_transform(X = df_tsne_x, y = df_tsne_y)\n\nsns.scatterplot(x=tsne_results[:,0], y = tsne_results[:,1], hue=train_df['target'])","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:16.145829Z","iopub.execute_input":"2022-06-28T12:00:16.146363Z","iopub.status.idle":"2022-06-28T12:00:45.833408Z","shell.execute_reply.started":"2022-06-28T12:00:16.146320Z","shell.execute_reply":"2022-06-28T12:00:45.832624Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"pca = PCA(n_components=2)\npca_data = train_df[['city_development_index', 'training_hours']]\npca_res = pca.fit_transform(pca_data)\n\npca_df = pd.DataFrame(data = pca_res, columns = ['principal component 1', 'principal component 2'])\n\npca_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:45.834371Z","iopub.execute_input":"2022-06-28T12:00:45.834573Z","iopub.status.idle":"2022-06-28T12:00:45.869922Z","shell.execute_reply.started":"2022-06-28T12:00:45.834552Z","shell.execute_reply":"2022-06-28T12:00:45.868955Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:45.871220Z","iopub.execute_input":"2022-06-28T12:00:45.871574Z","iopub.status.idle":"2022-06-28T12:00:45.877351Z","shell.execute_reply.started":"2022-06-28T12:00:45.871538Z","shell.execute_reply":"2022-06-28T12:00:45.876146Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nplt.figure(figsize=(10,10))\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=14)\nplt.xlabel('Principal Component - 1',fontsize=20)\nplt.ylabel('Principal Component - 2',fontsize=20)\nplt.title(\"Principal Component Analysis\",fontsize=20)\ntargets = [0.0, 1.0]\ncolors = ['r', 'g']\n\nfor target, color in zip(targets,colors):\n    indicesToKeep = train_df['target'] == target\n    plt.scatter(pca_df.loc[indicesToKeep, 'principal component 1']\n               , pca_df.loc[indicesToKeep, 'principal component 2'], c = color, s = 50)\n    \nplt.legend(targets,prop={'size': 10})","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:45.878969Z","iopub.execute_input":"2022-06-28T12:00:45.879763Z","iopub.status.idle":"2022-06-28T12:00:46.352213Z","shell.execute_reply.started":"2022-06-28T12:00:45.879707Z","shell.execute_reply":"2022-06-28T12:00:46.350952Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Prepare a balanced training set for the association rules\ntrain_df['target'] = train_df['target'].apply(lambda elem : '0' if elem == 0.0 else '1') # I've done this because \"get_dummies\" doesn't work with numerical binary fields\ntrain_df_asssoc_rules = train_df[train_df['target'] == '0'].sample(len(train_df[train_df['target'] == '1']), replace=False).append(train_df[train_df['target'] == '1'])\ntrain_df_asssoc_rules","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:46.353464Z","iopub.execute_input":"2022-06-28T12:00:46.353810Z","iopub.status.idle":"2022-06-28T12:00:46.402539Z","shell.execute_reply.started":"2022-06-28T12:00:46.353776Z","shell.execute_reply":"2022-06-28T12:00:46.401677Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"experiment = pd.get_dummies(train_df_asssoc_rules[['gender', 'relevent_experience', 'enrolled_university', 'education_level', \n                                                   'major_discipline', 'company_type', 'last_new_job', 'target']])\nexperiment.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:46.403593Z","iopub.execute_input":"2022-06-28T12:00:46.403903Z","iopub.status.idle":"2022-06-28T12:00:46.442559Z","shell.execute_reply.started":"2022-06-28T12:00:46.403870Z","shell.execute_reply":"2022-06-28T12:00:46.441567Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"support_table = apriori(experiment, min_support=0.3, use_colnames=True)\nsupport_table.sort_values(by='support', axis=0, ascending=False, inplace=True)\nsupport_table","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:46.444275Z","iopub.execute_input":"2022-06-28T12:00:46.444645Z","iopub.status.idle":"2022-06-28T12:00:46.508556Z","shell.execute_reply.started":"2022-06-28T12:00:46.444613Z","shell.execute_reply":"2022-06-28T12:00:46.507606Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"apriori_table = association_rules(support_table, metric=\"confidence\", min_threshold=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:46.509848Z","iopub.execute_input":"2022-06-28T12:00:46.510133Z","iopub.status.idle":"2022-06-28T12:00:46.520637Z","shell.execute_reply.started":"2022-06-28T12:00:46.510105Z","shell.execute_reply":"2022-06-28T12:00:46.519509Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"apriori_table.sort_values(by='support', axis=0, ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:46.522118Z","iopub.execute_input":"2022-06-28T12:00:46.522552Z","iopub.status.idle":"2022-06-28T12:00:46.567008Z","shell.execute_reply.started":"2022-06-28T12:00:46.522524Z","shell.execute_reply":"2022-06-28T12:00:46.565800Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"apriori_table.sort_values(by='confidence', axis=0, ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:46.568700Z","iopub.execute_input":"2022-06-28T12:00:46.568963Z","iopub.status.idle":"2022-06-28T12:00:46.592576Z","shell.execute_reply.started":"2022-06-28T12:00:46.568940Z","shell.execute_reply":"2022-06-28T12:00:46.591966Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"apriori_table.sort_values(by='lift', axis=0, ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:46.593709Z","iopub.execute_input":"2022-06-28T12:00:46.594162Z","iopub.status.idle":"2022-06-28T12:00:46.624670Z","shell.execute_reply.started":"2022-06-28T12:00:46.594125Z","shell.execute_reply":"2022-06-28T12:00:46.623823Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Association rules for the output column\n\napriori_table_target = pd.DataFrame(data=None, index=None, columns=apriori_table.columns)\nfor i in range(0, len(apriori_table)):\n    if ('target_0' in set(apriori_table.loc[i]['consequents']) or 'target_1' in set(apriori_table.loc[i]['consequents'])) and len(set(apriori_table.loc[i]['consequents'])) == 1:\n        apriori_table_target = apriori_table_target.append(apriori_table.loc[i])\n        \napriori_table_target = apriori_table_target.sort_values(by='confidence', axis=0, ascending=False)\napriori_table_target['antecedents'] = apriori_table_target['antecedents'].apply(func=lambda elem : tuple(elem))\napriori_table_target['consequents'] = apriori_table_target['consequents'].apply(func=lambda elem : tuple(elem))\napriori_table_target","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:46.626176Z","iopub.execute_input":"2022-06-28T12:00:46.626459Z","iopub.status.idle":"2022-06-28T12:00:46.795925Z","shell.execute_reply.started":"2022-06-28T12:00:46.626431Z","shell.execute_reply":"2022-06-28T12:00:46.794577Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# The rules with the highest confidence in relation to the output column\n'''\n\nShort commentary about interesting foundings:\n\nThe majority of people (57%) who are not enrolled at the moment in anything related to school/uni that have relevant experience don't want\nto change their job. However, these kind of people are in a minority in our training set (only 31% of the records/observations have the \nmentioned above characteristics).\n\nMost of the man prefer stability, so they don't want to change their job.\n\nIn general, the people who want to change their job are having a BSc Diploma, and the subject of the BSc is STEM related. Having a BSc in\nSTEM and wanting to change your job to Data Science is not surprising, but the fact that most of the correspondents are not willing to\nspecialize by doing a MSc or a PhD only proves that people still don't understand the proper requirements a field like DS has. Probably,\nmost of the participants in this sample are focusing on APIs, rather than learning more math.\n\n'''\n\napriori_table_target[apriori_table_target['confidence'] > 0.5]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:46.798935Z","iopub.execute_input":"2022-06-28T12:00:46.799202Z","iopub.status.idle":"2022-06-28T12:00:46.820050Z","shell.execute_reply.started":"2022-06-28T12:00:46.799176Z","shell.execute_reply":"2022-06-28T12:00:46.818693Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Visualisation of the association rules in relation to the output column\nheatmap_assoc = dict()\nfor metric in ('support', 'confidence', 'lift'):\n    heatmap_assoc[metric] = apriori_table_target.pivot(index='antecedents', columns='consequents', values=metric)\n\nfor metric in heatmap_assoc.keys():\n    fig = plt.figure(figsize = (15,5))\n    ax = fig.gca()\n    seaborn.heatmap(heatmap_assoc[metric], ax=ax).set_title(\"By \" + metric)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:46.828026Z","iopub.execute_input":"2022-06-28T12:00:46.828440Z","iopub.status.idle":"2022-06-28T12:00:47.706755Z","shell.execute_reply.started":"2022-06-28T12:00:46.828410Z","shell.execute_reply":"2022-06-28T12:00:47.706155Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# ------------------------------------------------------------------------------------------------------------------------------------------------------\n# Classification\n# ------------------------------------------------------------------------------------------------------------------------------------------------------","metadata":{}},{"cell_type":"code","source":"train_df.drop(columns=['enrollee_id'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:47.708097Z","iopub.execute_input":"2022-06-28T12:00:47.708449Z","iopub.status.idle":"2022-06-28T12:00:47.716412Z","shell.execute_reply.started":"2022-06-28T12:00:47.708415Z","shell.execute_reply":"2022-06-28T12:00:47.715348Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\nImage(filename=\"../input/poze-explicatii/feature_selection.png\", width= 700, height=500)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:47.719158Z","iopub.execute_input":"2022-06-28T12:00:47.719594Z","iopub.status.idle":"2022-06-28T12:00:47.893282Z","shell.execute_reply.started":"2022-06-28T12:00:47.719558Z","shell.execute_reply":"2022-06-28T12:00:47.892306Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"X = train_df[[quantitative[0], quantitative[2]]] \nY = train_df[train_df.columns[-1]]\nselect_k_best = SelectKBest(f_classif, k=2).fit(X, Y)\nprint(select_k_best.scores_) # F-value for each column; \n                             # BIG F-value => SMALL p-value => REJECT H_0 (a.k.a means are not equal) => the split of the values of a feature according to the label is signif\nX = select_k_best.transform(X) # Only the first k features were selected according to the descending ordder of their corresponding F-values \nprint(X)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:47.894938Z","iopub.execute_input":"2022-06-28T12:00:47.895248Z","iopub.status.idle":"2022-06-28T12:00:47.921416Z","shell.execute_reply.started":"2022-06-28T12:00:47.895219Z","shell.execute_reply":"2022-06-28T12:00:47.920787Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"train_df_chi2 = copy.deepcopy(train_df)\nfor elem in categorical[:-1]:\n    train_df_chi2[elem] = train_df_chi2[elem].astype('category')\ncat = train_df_chi2.select_dtypes(['category']).columns\ntrain_df_chi2[categorical[:-1]] = train_df_chi2[categorical[:-1]].apply(lambda elem : elem.cat.codes)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:47.922521Z","iopub.execute_input":"2022-06-28T12:00:47.922899Z","iopub.status.idle":"2022-06-28T12:00:47.974323Z","shell.execute_reply.started":"2022-06-28T12:00:47.922869Z","shell.execute_reply":"2022-06-28T12:00:47.973610Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"X = train_df_chi2[categorical[:-1]]\nY = train_df_chi2[train_df_chi2.columns[-1]]\nselect_k_best = SelectKBest(chi2, k=5).fit(X, Y)\nprint(select_k_best.scores_)\nX = select_k_best.transform(X)\nprint(X)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:47.975657Z","iopub.execute_input":"2022-06-28T12:00:47.975897Z","iopub.status.idle":"2022-06-28T12:00:48.027038Z","shell.execute_reply.started":"2022-06-28T12:00:47.975862Z","shell.execute_reply":"2022-06-28T12:00:48.026445Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"copie_original = copy.deepcopy(train_df)\n\nfor elem in categorical[:-1]:\n    train_df[elem] = train_df[elem].astype('category')\n\ntrain_df['target'] = train_df['target'].astype('int')","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:48.028160Z","iopub.execute_input":"2022-06-28T12:00:48.028376Z","iopub.status.idle":"2022-06-28T12:00:48.072421Z","shell.execute_reply.started":"2022-06-28T12:00:48.028354Z","shell.execute_reply":"2022-06-28T12:00:48.071448Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"train_df = pd.get_dummies(train_df, columns=categorical[:-1] + ['experience'])\n\nscaler = StandardScaler().fit(train_df[['city_development_index', 'training_hours']]).transform(train_df[['city_development_index', 'training_hours']])\ntrain_df['city_development_index'] = scaler[:, 0]\ntrain_df['training_hours'] = scaler[:, 1]\n\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:48.073363Z","iopub.execute_input":"2022-06-28T12:00:48.073654Z","iopub.status.idle":"2022-06-28T12:00:48.117926Z","shell.execute_reply.started":"2022-06-28T12:00:48.073630Z","shell.execute_reply":"2022-06-28T12:00:48.117182Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680\n\nDT_params = RandomizedSearchCV(estimator=DecisionTreeClassifier(class_weight='balanced'), param_distributions={'max_depth':         randint(5, 20),\n                                                                                                               'min_samples_split': randint(1, 40),\n                                                                                                               'min_samples_leaf':  randint(1, 20)},\n                               n_iter=1000, n_jobs=-1, cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=5))\n\nfilt = list(filter(lambda elem : elem != 'target', train_df.columns))            \nresult_DT = DT_params.fit(train_df[filt], train_df['target'])\npd.DataFrame(result_DT.cv_results_).loc[[result_DT.best_index_]]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:00:48.119252Z","iopub.execute_input":"2022-06-28T12:00:48.119800Z","iopub.status.idle":"2022-06-28T12:58:03.649646Z","shell.execute_reply.started":"2022-06-28T12:00:48.119763Z","shell.execute_reply":"2022-06-28T12:58:03.648146Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# help(sklearn.tree._tree.Tree)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:58:03.651329Z","iopub.execute_input":"2022-06-28T12:58:03.651690Z","iopub.status.idle":"2022-06-28T12:58:03.656704Z","shell.execute_reply.started":"2022-06-28T12:58:03.651650Z","shell.execute_reply":"2022-06-28T12:58:03.655514Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# https://machinelearningmastery.com/rfe-feature-selection-in-python/\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5)\nfilt = list(filter(lambda elem : elem != 'target', train_df.columns))\nselector = RFECV(result_DT.best_estimator_, step=1, min_features_to_select=10, cv=cv).fit(train_df[filt], train_df['target'])\nprint(selector.grid_scores_)\nprint(selector.support_)\nfor i in range(0, len(selector.support_)):\n    if selector.support_[i] == False:\n        train_df.drop(columns=filt[i], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T12:58:03.658545Z","iopub.execute_input":"2022-06-28T12:58:03.658909Z","iopub.status.idle":"2022-06-28T13:11:36.087228Z","shell.execute_reply.started":"2022-06-28T12:58:03.658873Z","shell.execute_reply":"2022-06-28T13:11:36.086343Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"\nclass ANN:\n    \n    \n    def __init__(self, train, valid, test, batch_size, epochs, learning_rate, nr_labels, neurons_per_layer: list, activation, \n                 optimizer, regularization, lambd, dropout):\n        \n        self.batch_size = batch_size; self.epochs = epochs; self.etha = learning_rate; self.nr_labels = nr_labels\n        self.neurons_per_layer = neurons_per_layer\n        \n        self.X_train = train[0]; self.Y_train = self.reshape_Y(train[1])\n        self.X_valid = valid[0]; self.Y_valid = self.reshape_Y(valid[1])\n        self.X_test = test[0];   self.Y_test = self.reshape_Y(test[1])\n        self.activation = activation; self.optimizer = optimizer.lower()\n        self.regularization = regularization; self.lambd = lambd\n        \n        if dropout is not None:\n            for key in dropout.keys():\n                dropout[key] = np.random.random_integers(low=0, high=self.neurons_per_layer[key]-1,\n                                                         size=(int)(dropout[key] * self.neurons_per_layer[key]))\n        self.dropout = dropout\n        \n        self.batches = self.split_in_batches(self.X_train, self.Y_train, self.batch_size)\n        \n        self.a = [None for _ in range(0, len(self.neurons_per_layer))]\n        self.W = [np.random.normal(0, np.sqrt(1/self.neurons_per_layer[i]), (self.neurons_per_layer[i+1], self.neurons_per_layer[i]))\n                  for i in range(0, len(self.neurons_per_layer) - 1)]\n        self.W.insert(0, None)\n        \n        if self.optimizer == 'momentum':\n            self.gamma, self.history = self.auxiliar_vars('momentum')\n        elif self.optimizer == 'adagrad':\n            self.epsilon, self.history = self.auxiliar_vars('adagrad')\n        elif self.optimizer == 'rmsprop':\n            self.epsilon, self.beta, self.history = self.auxiliar_vars('rmsprop')\n    \n    \n    def auxiliar_vars(self, optimizer):\n        history = [0 for _ in range(0, len(self.W))]\n        epsilon = 0.01\n        if optimizer == 'momentum':\n            gamma = 0.9\n            return (gamma, history)\n        if optimizer == 'rmsprop':\n            beta = 0.99\n            return (epsilon, beta, history)\n        return (epsilon, history)\n    \n    \n    def sigmoid(self, z):\n        return 1 / (1 + np.exp(-z))\n    \n    \n    def sigmoid_deriv(self, a):\n        return np.multiply(a, (1 - a))\n    \n    \n    def tanh(self, z):\n        return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n    \n    \n    def tanh_deriv(self, z):\n        return 1 - self.tanh(z) ** 2\n    \n    \n    def relu(self, z):\n        return np.array([list(map(lambda elem : 0 if elem <= 0 else elem, line)) for line in z])\n    \n    \n    def relu_deriv(self, a):\n        return np.array([list(map(lambda elem: 0 if elem == 0 else 1, line)) for line in a])\n    \n    \n    def softmax(self, z):\n        return np.exp(z) / np.sum(np.exp(z), axis=0)\n    \n    \n    def softmax_deriv(self, a):\n        return np.multiply(a, 1 - a)\n    \n    \n    def logistic_loss(self, last_layer, real_outputs):\n        rez = 0 - np.multiply(real_outputs, np.log(last_layer)) + np.multiply((1 - real_outputs), np.log(1 - last_layer))\n        return sum(np.sum(rez, axis=0))\n    \n    \n    def logistic_loss_deriv(self, last_layer, real_outputs):\n        return (last_layer - real_outputs) / np.multiply(last_layer, 1 - last_layer)\n    \n    \n    def forward_propagation(self, X):\n        self.a[0] = X\n        for i in range(1, len(self.a) - 1):\n            z = np.dot(self.W[i], self.a[i-1])\n            if self.activation == 'sigmoid':\n                self.a[i] = self.sigmoid(z)\n            elif self.activation == 'tanh':\n                self.a[i] = self.tanh(z)\n            elif self.activation == 'relu':\n                self.a[i] = self.relu(z)\n        i += 1\n        z = np.dot(self.W[i], self.a[i-1])\n        self.a[i] = self.softmax(z)\n\n        \n    def back_propagation(self, real_outputs):\n        W_before = copy.deepcopy(self.W)\n        gradients = []\n        error = (1 / self.batch_size) * (self.a[-1] - real_outputs)\n        if self.regularization == 'L2':\n            gradient = np.dot(error, self.a[-2].T) + self.lambd * (1 / self.batch_size) * self.W[-1]\n        elif self.regularization == 'L1':\n            gradient = np.dot(error, self.a[-2].T) + self.lambd * (1 / self.batch_size) * np.sign(self.W[-1])\n        gradients.append(gradient)\n        \n        for i in range(len(self.a) - 2, 0, -1):\n            if self.activation == 'sigmoid':\n                error = np.multiply(np.dot(error.T, self.W[i+1]).T, self.sigmoid_deriv(self.a[i]))\n            elif self.activation == 'tanh':\n                error = np.multiply(np.dot(error.T, self.W[i+1]).T, self.tanh_deriv(self.a[i]))\n            elif self.activation == 'relu':\n                error = np.multiply(np.dot(error.T, self.W[i+1]).T, self.relu_deriv(self.a[i]))\n            if self.regularization == 'L2':\n                gradient = np.dot(error, self.a[i-1].T) + self.lambd * (1 / self.batch_size) * self.W[i]\n            elif self.regularization == 'L1':\n                gradient = np.dot(error, self.a[i-1].T) + self.lambd * (1 / self.batch_size) * np.sign(self.W[i])\n            gradients.append(gradient)\n        \n        gradients = list(reversed(gradients))\n        gradients.insert(0, None)\n        \n        for i in range(1, len(self.a)):\n            if self.optimizer == 'momentum':\n                self.history[i] = self.gamma * self.history[i] + self.etha * gradients[i]\n                self.W[i] -= self.history[i]\n            else:\n                self.W[i] -=  (self.etha / np.sqrt(self.history[i] + self.epsilon)) * gradients[i]\n                if self.optimizer == 'adagrad':\n                    self.history[i] += gradients[i] ** 2\n                elif self.optimizer == 'rmsprop':\n                    self.history[i] = self.beta * self.history[i] + (1 - self.beta) * gradients[i] ** 2\n        \n        if self.dropout is not None:\n            for i in range(1, len(self.a) - 1):\n                if i in self.dropout.keys():\n                    for neuron in self.dropout[i]:\n                        self.W[i + 1][:, neuron] = copy.deepcopy(W_before[i + 1][:, neuron])\n                        self.W[i][neuron, :] = copy.deepcopy(W_before[i][neuron, :])\n        \n        \n    def fit(self):\n        for epoch in range(0, self.epochs):\n            for batch in self.batches:\n                self.forward_propagation(batch[0])\n                self.back_propagation(batch[1])\n            self.accuracy(self.X_train, self.Y_train, \"Train accuracy: \")\n            self.accuracy(self.X_valid, self.Y_valid, \"Valid accuracy: \")\n    \n    \n    def accuracy(self, X, Y, msg):\n        self.forward_propagation(X)\n        real = np.argmax(Y, axis=0)\n        predicted = np.argmax(self.a[-1], axis=0)\n        nr = 0\n        for i in range(0, real.size):\n            if real[i] == predicted[i]:\n                nr += 1\n        print(msg + str(nr / X.shape[1]))\n    \n    \n    def reshape_Y(self, vec):    \n        new_Y = np.zeros((self.nr_labels, len(vec)))\n        for i in range(0, len(vec)):\n            new_Y[vec[i], i] = 1\n        return new_Y\n    \n    \n    def split_in_batches(self, X, Y, batch_size):\n        batches = []\n        for i in range(0, X.shape[1], batch_size):\n            batches.append((X[:, i:i+batch_size], Y[:, i:i+batch_size]))\n        return batches\n\n    \nif __name__ == \"__main__\":\n    \n    X_ANN = train_df[filter(lambda elem : elem != 'target', train_df.columns)].values\n    Y_ANN = train_df['target'].values\n    X_ANN_train, X_ANN_test, Y_ANN_train, Y_ANN_test = train_test_split(X_ANN, Y_ANN, train_size=0.80, test_size=0.20, shuffle=True, stratify=Y_ANN)\n    X_ANN_train = X_ANN_train.T\n    X_ANN_test = X_ANN_test.T\n\n    var = ANN((X_ANN_train, Y_ANN_train), (X_ANN_test, Y_ANN_test), (X_ANN_test, Y_ANN_test), \n              batch_size=10, epochs=10, learning_rate=0.1, nr_labels=2, neurons_per_layer=[X_ANN_train.shape[0], 50, 50, 2], activation='relu',\n              optimizer='adagrad', regularization='L2', lambd=0.01, dropout=None)\n    var.fit()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:11:36.088514Z","iopub.execute_input":"2022-06-28T13:11:36.088801Z","iopub.status.idle":"2022-06-28T13:12:23.355925Z","shell.execute_reply.started":"2022-06-28T13:11:36.088771Z","shell.execute_reply":"2022-06-28T13:12:23.354542Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"X_gaussian_NB = train_df[['city_development_index', 'training_hours']]\nY_gaussian_NB = train_df['target']\ngaussian_NB = GaussianNB()\nscores = cross_validate(gaussian_NB, X_gaussian_NB, Y_gaussian_NB, scoring=['accuracy'], cv=StratifiedKFold(n_splits=10), return_estimator=True)\ngaussian_NB = scores['estimator'][np.argmax(scores['test_accuracy'])]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:12:23.357377Z","iopub.execute_input":"2022-06-28T13:12:23.357768Z","iopub.status.idle":"2022-06-28T13:12:23.430394Z","shell.execute_reply.started":"2022-06-28T13:12:23.357731Z","shell.execute_reply":"2022-06-28T13:12:23.429588Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"gaussian_NB.fit(X_gaussian_NB, Y_gaussian_NB)\ngaussian_NB_predictions = gaussian_NB.predict(X_gaussian_NB)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:12:23.431434Z","iopub.execute_input":"2022-06-28T13:12:23.431649Z","iopub.status.idle":"2022-06-28T13:12:23.441492Z","shell.execute_reply.started":"2022-06-28T13:12:23.431625Z","shell.execute_reply":"2022-06-28T13:12:23.440843Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"print(\"Balanced accuracy for Random Forest is: {bal_acc}\".format(bal_acc=balanced_accuracy_score(Y_gaussian_NB, gaussian_NB_predictions)))\nprint(classification_report(Y_gaussian_NB, gaussian_NB_predictions))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:12:23.442300Z","iopub.execute_input":"2022-06-28T13:12:23.442494Z","iopub.status.idle":"2022-06-28T13:12:23.490610Z","shell.execute_reply.started":"2022-06-28T13:12:23.442472Z","shell.execute_reply":"2022-06-28T13:12:23.489986Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"categorical_set = copy.deepcopy(copie_original)\nfilt = list(filter(lambda elem : elem not in ['city_development_index', 'training_hours', 'target', 'experience'], copie_original.columns))\ncategorical_set[filt] = OrdinalEncoder().fit_transform(categorical_set[filt])\n\nX_categorical_NB = categorical_set[filt]\nY_categorical_NB = categorical_set['target']\nY_categorical_NB = Y_categorical_NB.astype('int')\ncategorical_NB = CategoricalNB()\nscores = cross_validate(categorical_NB, X_categorical_NB, Y_categorical_NB, scoring=['accuracy'], cv=StratifiedKFold(n_splits=10), return_estimator=True)\ncategorical_NB = scores['estimator'][np.argmax(scores['test_accuracy'])]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:12:23.491535Z","iopub.execute_input":"2022-06-28T13:12:23.491830Z","iopub.status.idle":"2022-06-28T13:12:23.702099Z","shell.execute_reply.started":"2022-06-28T13:12:23.491807Z","shell.execute_reply":"2022-06-28T13:12:23.701492Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"categorical_NB.fit(X_categorical_NB, Y_categorical_NB)\ncategorical_NB_predictions = categorical_NB.predict(X_categorical_NB)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:12:23.702963Z","iopub.execute_input":"2022-06-28T13:12:23.703281Z","iopub.status.idle":"2022-06-28T13:12:23.725252Z","shell.execute_reply.started":"2022-06-28T13:12:23.703254Z","shell.execute_reply":"2022-06-28T13:12:23.724055Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"print(\"Balanced accuracy for Random Forest is: {bal_acc}\".format(bal_acc=balanced_accuracy_score(Y_categorical_NB, categorical_NB_predictions)))\nprint(classification_report(Y_categorical_NB, categorical_NB_predictions))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:12:23.726516Z","iopub.execute_input":"2022-06-28T13:12:23.726900Z","iopub.status.idle":"2022-06-28T13:12:23.789248Z","shell.execute_reply.started":"2022-06-28T13:12:23.726870Z","shell.execute_reply":"2022-06-28T13:12:23.788257Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"filt = list(filter(lambda elem : elem != 'target', train_df.columns))\nlogistic_regression = LogisticRegression(n_jobs=-1)\nlogistic_regression.fit(train_df[filt], train_df['target'])\n\n\nX_logistic = train_df[filt]\nY_logistic = train_df['target']\nlogistic_regression = LogisticRegression(penalty='l2', n_jobs=-1)\nscores = cross_validate(logistic_regression, X_logistic, Y_logistic, scoring=['accuracy'], cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=5), return_estimator=True, error_score='raise') \nlogistic_regression = scores['estimator'][np.argmax(scores['test_accuracy'])]\n\nlogistic_regression.fit(X_logistic, Y_logistic)\nlogistic_regression_predictions = logistic_regression.predict(X_logistic)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:12:23.790392Z","iopub.execute_input":"2022-06-28T13:12:23.790775Z","iopub.status.idle":"2022-06-28T13:12:58.188113Z","shell.execute_reply.started":"2022-06-28T13:12:23.790742Z","shell.execute_reply":"2022-06-28T13:12:58.186858Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"print(\"Balanced accuracy for Logistic Regression is: {bal_acc}\".format(bal_acc=balanced_accuracy_score(Y_logistic, logistic_regression_predictions)))\nprint(classification_report(Y_logistic, logistic_regression_predictions))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:12:58.189612Z","iopub.execute_input":"2022-06-28T13:12:58.189933Z","iopub.status.idle":"2022-06-28T13:12:58.235950Z","shell.execute_reply.started":"2022-06-28T13:12:58.189897Z","shell.execute_reply":"2022-06-28T13:12:58.235256Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\nImage(filename=\"../input/poze-explicatii/dt_questions.png\", width= 700, height=500)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:12:58.237232Z","iopub.execute_input":"2022-06-28T13:12:58.237717Z","iopub.status.idle":"2022-06-28T13:12:58.434096Z","shell.execute_reply.started":"2022-06-28T13:12:58.237683Z","shell.execute_reply":"2022-06-28T13:12:58.432907Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680\n\nDT_params = RandomizedSearchCV(estimator=DecisionTreeClassifier(class_weight='balanced'), param_distributions={'min_samples_split': randint(1, 40),\n                                                                                                               'min_samples_leaf':  randint(1, 20)},\n                               n_iter=10, n_jobs=-1, cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=1))\n\nfilt = list(filter(lambda elem : elem != 'target', train_df.columns))            \ndt_hyper_params = DT_params.fit(train_df[filt], train_df['target'])\npd.DataFrame(dt_hyper_params.cv_results_).loc[[dt_hyper_params.best_index_]]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:12:58.435361Z","iopub.execute_input":"2022-06-28T13:12:58.435634Z","iopub.status.idle":"2022-06-28T13:13:00.738275Z","shell.execute_reply.started":"2022-06-28T13:12:58.435607Z","shell.execute_reply":"2022-06-28T13:13:00.736947Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:13:00.739385Z","iopub.execute_input":"2022-06-28T13:13:00.739649Z","iopub.status.idle":"2022-06-28T13:13:00.761653Z","shell.execute_reply.started":"2022-06-28T13:13:00.739622Z","shell.execute_reply":"2022-06-28T13:13:00.760375Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (20,20))\nax = fig.gca()\n_ = sklearn.tree.plot_tree(dt_hyper_params.best_estimator_, ax=ax, fontsize=10)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:13:00.762996Z","iopub.execute_input":"2022-06-28T13:13:00.763401Z","iopub.status.idle":"2022-06-28T13:14:06.291651Z","shell.execute_reply.started":"2022-06-28T13:13:00.763321Z","shell.execute_reply":"2022-06-28T13:14:06.290646Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"best_dt = dt_hyper_params.best_estimator_\nX_dt = train_df[filt]\nY_dt = train_df['target']\nbest_dt.fit(X_dt, Y_dt)\ndt_predictions = best_dt.predict(X_dt)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:14:06.293045Z","iopub.execute_input":"2022-06-28T13:14:06.293365Z","iopub.status.idle":"2022-06-28T13:14:06.368199Z","shell.execute_reply.started":"2022-06-28T13:14:06.293337Z","shell.execute_reply":"2022-06-28T13:14:06.366480Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"print(\"Balanced accuracy for Decision Tree is: {bal_acc}\".format(bal_acc=balanced_accuracy_score(Y_dt, dt_predictions)))\nprint(classification_report(Y_dt, dt_predictions))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:14:06.369426Z","iopub.execute_input":"2022-06-28T13:14:06.369697Z","iopub.status.idle":"2022-06-28T13:14:06.458114Z","shell.execute_reply.started":"2022-06-28T13:14:06.369669Z","shell.execute_reply":"2022-06-28T13:14:06.456738Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"#max_features=sqrt recommended for classification\nRF_params = RandomizedSearchCV(estimator=RandomForestClassifier(max_features='sqrt', class_weight='balanced', bootstrap=True, n_jobs=-1), \n                               param_distributions={'n_estimators': randint(100, 500), 'min_samples_split': randint(1, 40), 'min_samples_leaf':  randint(1, 20)},\n                               n_iter=1, n_jobs=-1, cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=5))\n\nfilt = list(filter(lambda elem : elem != 'target', train_df.columns))            \nresult_RF = RF_params.fit(train_df[filt], train_df['target'])\npd.DataFrame(result_RF.cv_results_).loc[[result_RF.best_index_]]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:14:06.459614Z","iopub.execute_input":"2022-06-28T13:14:06.459886Z","iopub.status.idle":"2022-06-28T13:14:52.533014Z","shell.execute_reply.started":"2022-06-28T13:14:06.459858Z","shell.execute_reply":"2022-06-28T13:14:52.532176Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"best_rf = RF_params.best_estimator_\nX_rf = train_df[filt]\nY_rf = train_df['target']\nbest_rf.fit(X_rf, Y_rf)\nrf_predictions = best_rf.predict(X_rf)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:14:52.534221Z","iopub.execute_input":"2022-06-28T13:14:52.534639Z","iopub.status.idle":"2022-06-28T13:14:54.091369Z","shell.execute_reply.started":"2022-06-28T13:14:52.534611Z","shell.execute_reply":"2022-06-28T13:14:54.090484Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"print(\"Balanced accuracy for Random Forest is: {bal_acc}\".format(bal_acc=balanced_accuracy_score(Y_rf, rf_predictions)))\nprint(classification_report(Y_rf, rf_predictions))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:14:54.093648Z","iopub.execute_input":"2022-06-28T13:14:54.093915Z","iopub.status.idle":"2022-06-28T13:14:54.158842Z","shell.execute_reply.started":"2022-06-28T13:14:54.093888Z","shell.execute_reply":"2022-06-28T13:14:54.157742Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nbest_adaboost = AdaBoostClassifier(n_estimators=1000, )\nX_ada = train_df[filt]\nY_ada = train_df['target']\nbest_adaboost.fit(X_ada, Y_ada)\nada_predictions = best_adaboost.predict(X_ada)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:14:54.160056Z","iopub.execute_input":"2022-06-28T13:14:54.160441Z","iopub.status.idle":"2022-06-28T13:15:11.858260Z","shell.execute_reply.started":"2022-06-28T13:14:54.160405Z","shell.execute_reply":"2022-06-28T13:15:11.857369Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\nImage(filename=\"../input/poze-explicatii/adaboost.png\", width= 700, height=500)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:15:11.859525Z","iopub.execute_input":"2022-06-28T13:15:11.859791Z","iopub.status.idle":"2022-06-28T13:15:12.025387Z","shell.execute_reply.started":"2022-06-28T13:15:11.859765Z","shell.execute_reply":"2022-06-28T13:15:12.024692Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"print(\"Balanced accuracy for Adaboost is: {bal_acc}\".format(bal_acc=balanced_accuracy_score(Y_ada, ada_predictions)))\nprint(classification_report(Y_ada, ada_predictions))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:15:12.026267Z","iopub.execute_input":"2022-06-28T13:15:12.026542Z","iopub.status.idle":"2022-06-28T13:15:12.085658Z","shell.execute_reply.started":"2022-06-28T13:15:12.026519Z","shell.execute_reply":"2022-06-28T13:15:12.085142Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\nImage(filename=\"../input/poze-explicatii/svm_1.png\", width= 700, height=500)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:15:12.086545Z","iopub.execute_input":"2022-06-28T13:15:12.086850Z","iopub.status.idle":"2022-06-28T13:15:12.231031Z","shell.execute_reply.started":"2022-06-28T13:15:12.086827Z","shell.execute_reply":"2022-06-28T13:15:12.230184Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\nImage(filename=\"../input/poze-explicatii/svm_2.png\", width= 700, height=500)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:15:12.232177Z","iopub.execute_input":"2022-06-28T13:15:12.232602Z","iopub.status.idle":"2022-06-28T13:15:12.378310Z","shell.execute_reply.started":"2022-06-28T13:15:12.232570Z","shell.execute_reply":"2022-06-28T13:15:12.377337Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"SVM_params = RandomizedSearchCV(estimator=SVC(coef0=1, probability=True, cache_size=1000, class_weight='balanced', decision_function_shape='ovo', random_state=42), \n                                param_distributions = {'C' : scipy.stats.expon(scale=100), \n                                                       'kernel': ['linear', 'poly', 'rbf'],\n                                                       'degree': [2, 3],\n                                                       'gamma': scipy.stats.expon(scale=.1)},\n                                n_iter=1, n_jobs=-1, cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=1))\n\nfilt = list(filter(lambda elem : elem != 'target', train_df.columns))            \nsvm_hyper_params = SVM_params.fit(train_df[filt].loc[:1000], train_df['target'].loc[:1000])\nbest_svm = svm_hyper_params.best_estimator_\npd.DataFrame(svm_hyper_params.cv_results_).loc[[svm_hyper_params.best_index_]]","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:15:12.379304Z","iopub.execute_input":"2022-06-28T13:15:12.379637Z","iopub.status.idle":"2022-06-28T13:15:13.780156Z","shell.execute_reply.started":"2022-06-28T13:15:12.379604Z","shell.execute_reply":"2022-06-28T13:15:13.779087Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"best_svm = svm_hyper_params.best_estimator_\nX_svm = train_df[filt]\nY_svm = train_df['target']\nbest_svm.fit(train_df[filt].loc[:1000], train_df['target'].loc[:1000])\nsvm_predictions = best_svm.predict(X_svm)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:15:13.782015Z","iopub.execute_input":"2022-06-28T13:15:13.782599Z","iopub.status.idle":"2022-06-28T13:15:14.988512Z","shell.execute_reply.started":"2022-06-28T13:15:13.782567Z","shell.execute_reply":"2022-06-28T13:15:14.987434Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"print(\"Balanced accuracy for Random Forest is: {bal_acc}\".format(bal_acc=balanced_accuracy_score(Y_svm, svm_predictions)))\nprint(classification_report(Y_svm, svm_predictions))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:15:14.989830Z","iopub.execute_input":"2022-06-28T13:15:14.990130Z","iopub.status.idle":"2022-06-28T13:15:15.056500Z","shell.execute_reply.started":"2022-06-28T13:15:14.990100Z","shell.execute_reply":"2022-06-28T13:15:15.055417Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"\nprint(\"------------------------------- ROC Curve --------------------------------------------------------------\")\nfpr, tpr, thresholds = roc_curve(Y_gaussian_NB, gaussian_NB.predict_proba(X_gaussian_NB)[:, 1])\nfpr2, tpr2, thresholds2 = roc_curve(Y_categorical_NB, categorical_NB.predict_proba(X_categorical_NB)[:, 1])\nfpr3, tpr3, thresholds3 = roc_curve(Y_logistic, logistic_regression.predict_proba(X_logistic)[:, 1])\nfpr4, tpr4, thresholds4 = roc_curve(Y_dt, best_dt.predict_proba(X_dt)[:, 1])\nfpr5, tpr5, thresholds5 = roc_curve(Y_rf, best_rf.predict_proba(X_rf)[:, 1])\nfpr6, tpr6, tresholds6 = roc_curve(Y_svm, best_svm.predict_proba(X_svm)[:, 1])\nfpr7, tpr7, tresholds7 = roc_curve(Y_ada, best_adaboost.predict_proba(X_ada)[:, 1])\nplt.plot(fpr, tpr, label = \"ROC curve\")\nplt.plot(fpr2, tpr2, label = \"ROC curve\")\nplt.plot(fpr3, tpr3, label = \"ROC curve\")\nplt.plot(fpr4, tpr4, label = \"ROC curve\")\nplt.plot(fpr5, tpr5, label = \"ROC curve\")\nplt.plot(fpr6, tpr6, label = \"ROC curve\")\nplt.plot(fpr7, tpr7, label = \"ROC curve\")\nplt.legend([\"Gaussian Naive Bayes\", \"Categorical Naive Bayes\", \"Logistic Regression\", \"Decision Trees\", \"Random Forest\", \"SVM\", \"Adaboost\"])\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel(\"1 - specificity\")\nplt.ylabel(\"Sensitivity\")\nplt.show()\n# print(\"AUC for Gaussian Naive Bayes: %f\" % (roc_auc_score(y_test_nb, gnb.predict_proba(x_test_nb)[:, 1])))\n# print(\"AUC for Logistic Regression: %f\" % (roc_auc_score(y_test_general, logreg.predict_proba(x_test_general)[:, 1])))\n# print(\"AUC for Random Forest: %f\" % (roc_auc_score(y_test_general, RF.predict_proba(x_test_general)[:, 1])))\n# print(\"AUC for Decision Tree: %f\" % (roc_auc_score(y_test_general, DT.predict_proba(x_test_general)[:, 1])))\n# print(\"AUC for DT&SVM: %f\" % (roc_auc_score(y_test_for_both, np.concatenate((y_pred_SVM_proba[:, 1], DT.predict_proba(x_test_for_DT)[:, 1])))))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:15:15.058986Z","iopub.execute_input":"2022-06-28T13:15:15.059404Z","iopub.status.idle":"2022-06-28T13:15:18.230818Z","shell.execute_reply.started":"2022-06-28T13:15:15.059372Z","shell.execute_reply":"2022-06-28T13:15:18.230041Z"},"trusted":true},"execution_count":69,"outputs":[]}]}